{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dde97b77-3936-42fe-b648-dbb7011a97bb",
   "metadata": {},
   "source": [
    "Q1.What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce2c726-6ebb-4c83-9ba6-5b8257049835",
   "metadata": {},
   "source": [
    "Ans.The Probability Mass Function (PMF) and Probability Density Function (PDF) are concepts used in probability theory and statistics to describe the probability distribution of a random variable.\n",
    "\n",
    "\n",
    "1.Probability Mass Function (PMF):\n",
    "The PMF is used for discrete random variables, which take on a countable number of possible values. It gives the probability that a random variable takes on a specific value.\n",
    "\n",
    "For example, let's consider rolling a fair six-sided die. The random variable \"X\" represents the outcome of the roll. The PMF of X would be:\n",
    "\n",
    "PMF(X = 1) = 1/6\n",
    "PMF(X = 2) = 1/6\n",
    "PMF(X = 3) = 1/6\n",
    "PMF(X = 4) = 1/6\n",
    "PMF(X = 5) = 1/6\n",
    "PMF(X = 6) = 1/6\n",
    "\n",
    "This means that each outcome (1, 2, 3, 4, 5, or 6) has an equal probability of 1/6.\n",
    "\n",
    "2.Probability Density Function (PDF):\n",
    "The PDF is used for continuous Random Variables,which take can any value within a spesific range\n",
    " for example,\n",
    " Height of student in classroom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5c3178-1a72-4f09-99fb-cd83082f6209",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a5e150-ecda-4090-b5fd-65cc5f7fc593",
   "metadata": {},
   "source": [
    "Ans.The Cumulative Distribution Function (CDF) is a concept used in probability theory and statistics. It provides information about the probability that a random variable takes on a value less than or equal to a specific value. In other words, the CDF gives the cumulative probability up to a certain point.\n",
    "\n",
    "The CDF is denoted by F(x), where x is the value at which we want to evaluate the cumulative probability. It is defined for both discrete and continuous random variables.\n",
    "\n",
    "Let's explain the CDF with an example:\n",
    "\n",
    "Consider a random variable \"X\" representing the score obtained on a test, which can range from 0 to 100. Let's assume the scores are normally distributed with a mean of 70 and a standard deviation of 10. To find the cumulative probability using the CDF:\n",
    "\n",
    "For a discrete random variable:\n",
    "If we want to find the probability that the score is less than or equal to 80, we evaluate the CDF at x = 80:\n",
    "CDF(X ≤ 80) = F(80)\n",
    "\n",
    "This value represents the cumulative probability of obtaining a score less than or equal to 80.\n",
    "\n",
    "For a continuous random variable:\n",
    "If we want to find the probability that the score is less than or equal to 80, we evaluate the CDF at x = 80:\n",
    "CDF(X ≤ 80) = F(80)\n",
    "\n",
    "In this case, the CDF represents the area under the probability density curve up to the value of 80.\n",
    "\n",
    "Why is the CDF used?\n",
    "The CDF is used for several reasons:\n",
    "\n",
    "Calculating probabilities: The CDF allows us to determine the probability of a random variable falling within a specific range. By subtracting the CDF values at two different points, we can find the probability of the random variable lying between those two points.\n",
    "\n",
    "Analyzing distributions: The CDF provides a comprehensive overview of the distribution of a random variable. It shows how the probabilities accumulate as the values of the random variable increase.\n",
    "\n",
    "Assessing percentiles: The CDF helps determine percentiles or quantiles of a distribution. For example, we can find the score below which a certain percentage of students fall.\n",
    "\n",
    "In summary, the Cumulative Distribution Function (CDF) gives the probability that a random variable takes on a value less than or equal to a specific value. It is useful for calculating probabilities, analyzing distributions, and determining percentiles of a random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f171a4b7-c666-401c-8297-528c7773d998",
   "metadata": {},
   "source": [
    "Q3.What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879a7cb-ffd5-4ab4-8287-95ee1c054683",
   "metadata": {},
   "source": [
    "Ans.The normal distribution, also known as the Gaussian distribution or bell curve, is a widely used statistical distribution that is applicable in various situations. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "Heights and weights: The distribution of adult heights and weights often follows a normal distribution, with the majority of individuals clustered around the mean value.\n",
    "\n",
    "IQ scores: IQ scores are commonly assumed to follow a normal distribution, with the mean set at 100 and a standard deviation of 15.\n",
    "\n",
    "Errors in measurement: Measurement errors in many scientific experiments or surveys tend to be normally distributed around the true value.\n",
    "\n",
    "Test scores: In large-scale educational testing, such as standardized tests, the scores of a large population of test-takers are often modeled using a normal distribution.\n",
    "\n",
    "Financial markets: In finance, stock returns or asset prices are often assumed to be normally distributed to simplify modeling and analysis.\n",
    "\n",
    "The parameters of the normal distribution are the mean (μ) and the standard deviation (σ). They play a crucial role in determining the shape of the distribution:\n",
    "\n",
    "Mean (μ): The mean represents the center of the distribution. It indicates the most probable value or the average value around which the data points tend to cluster. It determines the location of the peak of the bell curve.\n",
    "\n",
    "Standard deviation (σ): The standard deviation represents the spread or dispersion of the data. It measures how tightly or loosely the data points are distributed around the mean. A larger standard deviation indicates greater variability, resulting in a wider and flatter curve, while a smaller standard deviation leads to a narrower and taller curve.\n",
    "\n",
    "Together, the mean and standard deviation fully characterize the normal distribution. They determine the shape, location, and spread of the bell curve, allowing us to understand the probabilities associated with different values within the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80690636-60b5-4864-8ee3-7b343bf491dd",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbabc7-9b8e-4424-ab72-368e4e246166",
   "metadata": {},
   "source": [
    "ANS. The normal distribution, also known as the Gaussian distribution or bell curve, holds significant importance in various fields due to its mathematical properties and its tendency to arise naturally in many real-life situations.\n",
    "\n",
    "1.Central Limit Theorem: The normal distribution plays a crucial role in the Central Limit Theorem. According to this theorem, the sum or average of a large number of independent and identically distributed random variables will be approximately normally distributed, regardless of the underlying distribution of the individual variable.\n",
    "\n",
    "2.Simplified modeling: The normal distribution is often used as an approximation or a convenient model for complex real-life phenomena.\n",
    "\n",
    "3.Statistical inference: In hypothesis testing and confidence interval estimation, assumptions about the underlying distribution are often made. The normal distribution is frequently chosen due to its well-known properties, making statistical inference procedures more tractable and reliable. Many statistical tests and confidence intervals are derived based on the assumption of normality\n",
    "\n",
    "\n",
    "Real life Example,\n",
    "\n",
    "1. IQ scores: IQ scores are often assumed to follow a normal distribution. The distribution has a mean of 100 and a standard deviation of 15, which allows for the comparison of an individual's IQ score to the population's distribution.\n",
    "\n",
    "2. Heights and weights: The distribution of adult heights and weights often approximates a normal distribution, with most individuals clustered around the mean values. This property enables the calculation of percentiles, such as finding the percentage of the population within a specific height or weight range.\n",
    "\n",
    "3. Errors in measurements: In scientific experiments or surveys, measurement errors often exhibit a normal distribution. This assumption is used in statistical analysis to quantify uncertainties and make inferences about the true values being measured.\n",
    "\n",
    "4. Test scores: Standardized tests, such as college entrance exams or IQ tests, are designed to follow a normal distribution. This allows for the comparison of an individual's performance relative to the population of test-takers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0391d0b0-b5d4-4b2c-b845-fc2d19578702",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94e1cb1-8137-4cda-ad93-7dfbf28965fd",
   "metadata": {},
   "source": [
    "Ans. The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success (usually denoted as 1) or failure (usually denoted as 0).\n",
    "\n",
    "1. This is The  Descrete Random Variable.\n",
    "2. Outcomes are Binary.\n",
    "\n",
    "for example,\n",
    "\n",
    "Tossing a coin {H,T}\n",
    "\n",
    "parameter:\n",
    "\n",
    "0<=P<=1\n",
    "\n",
    "q=1-p\n",
    "\n",
    "k={0,1}\n",
    "\n",
    "PMF:\n",
    "\n",
    "PMF=p^k*(1-p)^(1-k)\n",
    "\n",
    "Mean of Bernoulli distribution:\n",
    "E(K) = p=mean\n",
    "\n",
    "Variance And Standard deviation of Bernoulli ditribution :\n",
    "\n",
    "var =  p*q\n",
    "\n",
    "std = (p*q)^1/2\n",
    "\n",
    "Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "\n",
    "1.Number of trials:\n",
    "The Bernoulli distribution describes a single random experiment with two possible outcomes (success or failure). It is suitable for modeling a single trial.\n",
    "The binomial distribution, on the other hand, describes the number of successes in a fixed number of independent Bernoulli trials. It is used when there are multiple independent trials, each with the same probability of succes\n",
    "\n",
    "2.\n",
    "Number of trials:\n",
    "The Bernoulli distribution describes a single random experiment with two possible outcomes (success or failure). It is suitable for modeling a single trial.\n",
    "The binomial distribution, on the other hand, describes the number of successes in a fixed number of independent Bernoulli trials. It is used when there are multiple independent trials, each with the same probability of success. The binomial distribution models the total number of successes over a specified number of trials.\n",
    "\n",
    "Number of parameters:\n",
    "The Bernoulli distribution has a single parameter, p, which represents the probability of success in a single trial.\n",
    "The binomial distribution has two parameters: n and p. The parameter n represents the number of trials, and p represents the probability of success in each individual trial.\n",
    "\n",
    "Probability mass function:\n",
    "The probability mass function (PMF) of the Bernoulli distribution has two possible values: p^1 * (1-p)^0 = p (for x = 1) and p^0 * (1-p)^1 = (1-p) (for x = 0).\n",
    "The probability mass function (PMF) of the binomial distribution is given by the formula:\n",
    "\n",
    "P(X = k) = (n choose k) * p^k * (1-p)^(n-k)\n",
    "\n",
    "where X is the random variable representing the number of successes, k is the number of successes, n is the number of trials, p is the probability of success in each trial, and (n choose k) is the binomial coefficient.\n",
    "\n",
    "In summary, the Bernoulli distribution models a single trial with two possible outcomes, while the binomial distribution models the total number of successes over a fixed number of independent trials with the same probability of success. The binomial distribution generalizes the Bernoulli distribution to multiple trials.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db04926-4e2d-4562-a84e-fe3d9117f2b0",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "232f9511-8af6-4362-8a68-bb94b0f8bc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of X > 60: 0.15865525393145707\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "mean = 50\n",
    "std_dev = 10\n",
    "x = 60\n",
    "\n",
    "# Calculate the z-score\n",
    "z = (x - mean) / std_dev\n",
    "\n",
    "# Calculate the cumulative probability\n",
    "probability = 1 - stats.norm.cdf(z)\n",
    "\n",
    "print(\"Probability of X > 60:\", probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b3912-72c8-4777-a95e-f24ea42855ed",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbc083-687a-4d39-8998-d399e15c3155",
   "metadata": {},
   "source": [
    "Ans.The uniform distribution is a probability distribution where all outcomes within a given range have an equal probability of occurring. It is characterized by a constant probability density function (PDF) over the range of possible values.\n",
    "\n",
    "Example:\n",
    "Consider rolling a fair six-sided die. The outcome of rolling the die follows a uniform distribution because each of the six faces has an equal probability of landing face-up. Each face has a probability of 1/6 or approximately 0.1667.\n",
    "\n",
    "\n",
    "The probability density function (PDF) of the uniform distribution is a constant function within the range of possible values and zero outside that range. For a continuous uniform distribution over the interval [a, b], the PDF is given by:\n",
    "\n",
    "f(x) = 1 / (b - a), for a ≤ x ≤ b\n",
    "f(x) = 0, otherwise\n",
    "\n",
    "The cumulative distribution function (CDF) of the uniform distribution is a linear function that increases steadily over the range. For a continuous uniform distribution, the CDF is given by:\n",
    "\n",
    "F(x) = (x - a) / (b - a), for a ≤ x ≤ b\n",
    "F(x) = 0, for x < a\n",
    "F(x) = 1, for x ≥ b\n",
    "\n",
    "Mean And Median :\n",
    "\n",
    "Mean  = (a+b)/2 = Median\n",
    "\n",
    "Variance = (b-a)^2/12\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430b85d-48cd-42a7-928a-f84efed0f0d2",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a52ee28-caf8-4538-816e-02852c578636",
   "metadata": {},
   "source": [
    "\n",
    "The z-score, also known as the standard score, is a statistical measure that quantifies how many standard deviations a data point is away from the mean of a distribution. It is a standardized value that allows for comparison and interpretation of data across different distributions.\n",
    "\n",
    "The formula to calculate the z-score is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where:\n",
    "\n",
    "z is the z-score\n",
    "x is the data point\n",
    "μ is the mean of the distribution\n",
    "σ is the standard deviation of the distribution\n",
    "The importance of the z-score lies in its ability to provide a standardized measure of how an individual data point relates to the overall distribution. Here are some key reasons why the z-score is important:\n",
    "\n",
    "1. Standardization and Comparison: The z-score standardizes data by transforming it into a common scale. This allows for the comparison of data points from different distributions or with different units of measurement. By using z-scores, we can compare data points across various contexts and identify outliers or extreme values.\n",
    "\n",
    "2. Probability and Percentile Calculation: The z-score helps in calculating probabilities and percentiles associated with a specific data point in a normal distribution. By converting data points to z-scores, we can use standard normal distribution tables or statistical software to determine the probability of observing a value or the percentage of data below or above a certain threshold.\n",
    "\n",
    "3. Identifying Outliers: The z-score is used to identify outliers, which are data points that deviate significantly from the mean of a distribution. Typically, values with z-scores greater than a certain threshold (e.g., ±2 or ±3) are considered outliers.\n",
    "\n",
    "4. Hypothesis Testing: In hypothesis testing, the z-score is used to assess the statistical significance of a sample mean or difference between sample means. By comparing the calculated z-score to critical values, we can determine whether the observed difference is statistically significant.\n",
    "\n",
    "5. Data Transformation: The z-score allows for data transformation, enabling the normalization of data that might not follow a normal distribution. This transformation can be helpful when applying certain statistical techniques that assume normality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8545d81-11c3-4daa-bf58-3375368c1b0f",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82407e8a-cab1-4ef0-9ab3-200ca61fe0e2",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that, under certain conditions, the sampling distribution of the sample mean approaches a normal distribution, regardless of the shape of the population distribution. In other words, when independent random samples are drawn from any population with a finite mean and standard deviation, the distribution of the sample means will be approximately normal, regardless of the population distribution's shape.\n",
    "\n",
    "The Central Limit Theorem has the following key properties:\n",
    "\n",
    "Sample Size: As the sample size increases, the distribution of the sample mean approaches a normal distribution, regardless of the shape of the population distribution. This property holds as long as the sample size is reasonably large (typically considered n ≥ 30).\n",
    "\n",
    "Independence: The individual observations within each sample should be independent or nearly independent of each other.\n",
    "\n",
    "Finite Population: The population should have a finite mean and standard deviation.\n",
    "\n",
    "The significance of the Central Limit Theorem can be understood through its practical implications:\n",
    "\n",
    "Statistical Inference: The Central Limit Theorem is a foundation for statistical inference. It allows us to make assumptions about the behavior of sample means and proportions, even when the population distribution is unknown or non-normal. It forms the basis for various hypothesis tests, confidence intervals, and p-value calculations.\n",
    "\n",
    "Normal Approximation: The Central Limit Theorem enables the use of the normal distribution as an approximation for the sampling distribution of the sample mean. This approximation is extremely useful because the properties of the normal distribution are well-documented and understood, making statistical calculations and analysis more tractable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ef39ba-1676-45c6-b403-2be27548d967",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd20a0d-e4fd-416a-a735-48743803f02f",
   "metadata": {},
   "source": [
    "Ans. Random Sampling: The observations in the sample are obtained through a random sampling process. This means that each observation is selected independently and has an equal chance of being selected.\n",
    "\n",
    "2. Independence: The individual observations within each sample are assumed to be independent of each other. This assumption implies that the value of one observation does not influence or depend on the value of another observation.\n",
    "\n",
    "3. Sample Size: The sample size should be reasonably large. While there is no strict cutoff, a common rule of thumb is that the Central Limit Theorem holds well when the sample size is greater than or equal to 30. However, this guideline can vary depending on the nature of the population distribution.\n",
    "\n",
    "4. Finite Population: The population from which the samples are drawn should have a finite mean and standard deviation. In practical applications, this assumption is often satisfied as long as the population is not extremely skewed or contains extreme outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addab4fc-851c-4c2c-acf2-ccc81d444a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
